{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[ref](https://github.com/xiaopeng-liao/DEC_pytorch)"
      ],
      "metadata": {
        "id": "5RBoDSX5lysU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Lad9T-9GloNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d54c36-1452-49c3-f742-e7f901f99416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Cedaj1D1eCQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHr9LXkBVCws"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "SMeLrqLHiuan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Dataloader for the GW Dataset"
      ],
      "metadata": {
        "id": "gZ9x69tDV8lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, root_dir):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.filelist = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filelist)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.filelist.iloc[idx, 0])\n",
        "        sample = io.imread(img_name)\n",
        "        label = self.filelist.iloc[idx, 1]\n",
        "        # landmarks = np.array([landmarks])\n",
        "        # landmarks = landmarks.astype('float').reshape(-1, 2)\n",
        "        # sample = {'image': image, 'label': label}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample, label"
      ],
      "metadata": {
        "id": "1AmnnP0Ph7_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrain Model Data"
      ],
      "metadata": {
        "id": "tROBJNx2pPKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## UPPER Atmospheric Data\n",
        "train_csv = '/content/drive/MyDrive/Seraj/upper-atmospheric-128/skybased-128-pretrain/pretrain_sky_train.csv'\n",
        "test_csv = '/content/drive/MyDrive/Seraj/upper-atmospheric-128/skybased-128-pretrain/pretrain_sky_test.csv'\n",
        "root_dir = '/content/drive/MyDrive/Seraj/upper-atmospheric-128/skybased-128-pretrain'"
      ],
      "metadata": {
        "id": "S5WZwgTm0YYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "\n",
        "train_set = MyDataset(train_csv,root_dir)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=train_set,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=True)\n",
        "\n",
        "test_set = MyDataset(test_csv, root_dir)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=test_set,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=True)\n",
        "\n",
        "data_sample = test_loader.dataset[0]\n",
        "x,y = data_sample\n",
        "print(x.shape)\n",
        "# print(len(test_loader))"
      ],
      "metadata": {
        "id": "tnTeyuvvnOVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd682d2e-256d-4b83-f6ec-fd68b3a06013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcFalkkSVCwy"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "timingResult = {}\n",
        "def logTime(theName, currentTime):\n",
        "    if theName not in timingResult:\n",
        "        timingResult[theName] = time.time() - currentTime\n",
        "    else:\n",
        "        timingResult[theName] = timingResult[theName] + (time.time() - currentTime)\n",
        "    currentTime = time.time()\n",
        "    return currentTime\n",
        "\n",
        "def printTiming(name):\n",
        "    print('======== timing for {}: {} ======='.format(name,timingResult[name]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr1hbrlyVCwz"
      },
      "outputs": [],
      "source": [
        "class DEC_AE(nn.Module):\n",
        "    def __init__(self, num_classes, num_features):\n",
        "        super(DEC_AE,self).__init__()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        # self.dropout = nn.AlphaDropout(0.5)\n",
        "        # self.fc1 = nn.Linear(1000*1000*4,500)\n",
        "        # self.fc1 = nn.Linear(28*28*1,500)\n",
        "        self.fc1 = nn.Linear(128*128*1,500)\n",
        "        # self.fc1 = nn.Linear(512*512*1,500)\n",
        "        self.fc2 = nn.Linear(500,500)\n",
        "        self.fc3 = nn.Linear(500,2000)\n",
        "        self.fc4 = nn.Linear(2000,num_features)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        # self.fc_d1 = nn.Linear(500,1000*1000*4)\n",
        "        # self.fc_d1 = nn.Linear(500,28*28*1)\n",
        "        self.fc_d1 = nn.Linear(500,128*128*1)\n",
        "        # self.fc_d1 = nn.Linear(500,512*512*1)\n",
        "        self.fc_d2 = nn.Linear(500,500)\n",
        "        self.fc_d3 = nn.Linear(2000,500)\n",
        "        self.fc_d4 = nn.Linear(num_features,2000)\n",
        "        self.alpha = 1.0\n",
        "        self.clusterCenter = nn.Parameter(torch.zeros(num_classes,num_features))\n",
        "        self.pretrainMode = True\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                torch.nn.init.xavier_uniform(m.weight)\n",
        "\n",
        "    def setPretrain(self,mode):\n",
        "        \"\"\"To set training mode to pretrain or not, \n",
        "        so that it can control to run only the Encoder or Encoder+Decoder\"\"\"\n",
        "        self.pretrainMode = mode\n",
        "    def updateClusterCenter(self, cc):\n",
        "        \"\"\"\n",
        "        To update the cluster center. This is a method for pre-train phase.\n",
        "        When a center is being provided by kmeans, we need to update it so\n",
        "        that it is available for further training\n",
        "        :param cc: the cluster centers to update, size of num_classes x num_features\n",
        "        \"\"\"\n",
        "        self.clusterCenter.data = torch.from_numpy(cc)\n",
        "    def getTDistribution(self,x, clusterCenter):\n",
        "        \"\"\"\n",
        "        student t-distribution, as same as used in t-SNE algorithm.\n",
        "         q_ij = 1/(1+dist(x_i, u_j)^2), then normalize it.\n",
        "         \n",
        "         :param x: input data, in this context it is encoder output\n",
        "         :param clusterCenter: the cluster center from kmeans\n",
        "         \"\"\"\n",
        "        xe = torch.unsqueeze(x,1).cuda() - clusterCenter.cuda()\n",
        "        q = 1.0 / (1.0 + (torch.sum(torch.mul(xe,xe), 2) / self.alpha))\n",
        "        q = q ** (self.alpha + 1.0) / 2.0\n",
        "        q = (q.t() / torch.sum(q, 1)).t() #due to divison, we need to transpose q\n",
        "        return q\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # x = x.view(-1, 1*28*28)\n",
        "        x = x.view(-1,1*128*128)\n",
        "        # x = x.view(-1,1*512*512)\n",
        "        # x = x.view(-1, 4*1000*1000)\n",
        "        # 32x32x1\n",
        "        x = self.dropout(x)\n",
        "        # 32x32x1\n",
        "        x = self.fc1(x)\n",
        "        # 17x17x50\n",
        "        x = self.relu(x)\n",
        "        # 17x17x50\n",
        "        x = self.fc2(x)\n",
        "        # 17x17x50\n",
        "        x = self.relu(x)\n",
        "        # 9x9x50\n",
        "        x = self.fc3(x)\n",
        "        # 17x17x50\n",
        "        x = self.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        # 9x9x50\n",
        "        x_ae = x\n",
        "        #if not in pretrain mode, we only need encoder\n",
        "        if self.pretrainMode == False:\n",
        "            return x, self.getTDistribution(x,self.clusterCenter)\n",
        "        # 1x68\n",
        "        ##### encoder is done, followed by decoder #####\n",
        "        # 1x68\n",
        "        x = self.fc_d4(x)\n",
        "        # 1x4050\n",
        "        x = self.relu(x)\n",
        "        # 1x4050\n",
        "        x = self.fc_d3(x)\n",
        "        # 1x4050\n",
        "        x = self.relu(x)\n",
        "        x = self.fc_d2(x)\n",
        "        # 1x4050\n",
        "        x = self.relu(x)\n",
        "        x = self.fc_d1(x)\n",
        "        # x_de = x.view(-1,1,28,28)\n",
        "        x_de = x.view(-1,1,128,128)\n",
        "        # x_de = x.view(-1,1,512,512)\n",
        "        # x_de = x.view(-1, 4*1000*1000)\n",
        "        # x_de = torch.reshape(x,(-1,1,128,128)) ## for testing\n",
        "        # 1x4050\n",
        "        return x_ae, x_de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDJXgDDCVCw1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
        "\n",
        "nmi = normalized_mutual_info_score\n",
        "ari = adjusted_rand_score\n",
        "\n",
        "def acc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate clustering accuracy. Require scikit-learn installed\n",
        "    # Arguments\n",
        "        y: true labels, numpy.array with shape `(n_samples,)`\n",
        "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
        "    # Return\n",
        "        accuracy, in [0,1]\n",
        "    \"\"\"\n",
        "    y_true = y_true.astype(np.int64)\n",
        "    assert y_pred.size == y_true.size\n",
        "    D = max(y_pred.max(), y_true.max()) + 1\n",
        "    w = np.zeros((D, D), dtype=np.int64)\n",
        "    for i in range(y_pred.size):\n",
        "        w[y_pred[i], y_true[i]] += 1\n",
        "    # from sklearn.utils.linear_assignment_ import linear_assignment\n",
        "    from scipy.optimize import linear_sum_assignment as linear_assignment\n",
        "    ind = linear_assignment(w.max() - w)\n",
        "    a, b =ind\n",
        "    # print(w.shape)\n",
        "    # print(ind)\n",
        "    temp=0\n",
        "    for i in range(len(a)):\n",
        "      temp += np.sum(w[a[i], b[i]])\n",
        "    # return np.sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size\n",
        "    return (temp* 1.0 / y_pred.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIm94BV7VCw2"
      },
      "outputs": [],
      "source": [
        "class DEC:\n",
        "    \"\"\"The class for controlling the training process of DEC\"\"\"\n",
        "    def __init__(self,n_clusters,alpha=1.0):\n",
        "        self.n_clusters=n_clusters\n",
        "        self.alpha = alpha\n",
        "        \n",
        "    @staticmethod\n",
        "    def target_distribution(q):\n",
        "        weight = q ** 2 / q.sum(0)\n",
        "        #print('q',q)\n",
        "        return Variable((weight.t() / weight.sum(1)).t().data, requires_grad=True)\n",
        "    def logAccuracy(self,pred,label):\n",
        "        print(' '*8 + '|==>  acc: %.4f,  nmi: %.4f  <==|'\n",
        "          % (acc(label, pred), nmi(label, pred)))\n",
        "    @staticmethod\n",
        "    def kld(q,p):\n",
        "        res = torch.sum(p*torch.log(p/q),dim=-1)\n",
        "        # res = torch.sum(p*torch.log(p)-q*torch.log(q),dim=-1)\n",
        "        return res\n",
        "    \n",
        "    def validateOnCompleteTestData(self,test_loader,model):\n",
        "        model.eval()\n",
        "        to_eval = np.array([model(d[0].cuda())[0].data.cpu().numpy() for i,d in enumerate(test_loader)])\n",
        "        # print(\"++++++++++++++++++\", to_eval.shape)\n",
        "        true_labels = np.array([d[1].cpu().numpy() for i,d in enumerate(test_loader)])\n",
        "        # print(\"++++++++++++++++++\", true_labels.shape)\n",
        "        to_eval = np.reshape(to_eval,(to_eval.shape[0]*to_eval.shape[1],to_eval.shape[2]))\n",
        "        # to_eval = np.reshape(to_eval,(to_eval.shape[0]*to_eval.shape[1]))\n",
        "        true_labels = np.reshape(true_labels,true_labels.shape[0]*true_labels.shape[1])\n",
        "        km = KMeans(n_clusters=len(np.unique(true_labels)), n_init=20)\n",
        "        y_pred = km.fit_predict(to_eval)\n",
        "        print(' '*8 + '|==>  acc: %.4f,  nmi: %.4f  <==|'\n",
        "                      % (acc(true_labels, y_pred), nmi(true_labels, y_pred)))\n",
        "        currentAcc = acc(true_labels, y_pred)\n",
        "        return currentAcc\n",
        "    \n",
        "    def pretrain(self,train_loader, test_loader, epochs):\n",
        "        # dec_ae = DEC_AE(10,10).cuda() #auto encoder\n",
        "        dec_ae = DEC_AE(2,10).cuda()\n",
        "        mseloss = nn.MSELoss()\n",
        "        optimizer = optim.SGD(dec_ae.parameters(),lr = 0.0001, momentum=0.9)\n",
        "        best_acc = 0.0\n",
        "        for epoch in range(epochs):\n",
        "            dec_ae.train()\n",
        "            running_loss=0.0\n",
        "            for i,data in enumerate(train_loader):\n",
        "                # print(\"I am here\")\n",
        "                x, label = data\n",
        "                x, label = Variable(x).cuda(),Variable(label).cuda()\n",
        "                optimizer.zero_grad()\n",
        "                x_ae,x_de = dec_ae(x)\n",
        "                # x = np.reshape(x,(batch_size,-1))\n",
        "                # x =torch.reshape(x,(batch_size,128*128))\n",
        "                # print(x.shape)\n",
        "                loss = F.mse_loss(x_de,x,reduce=True) \n",
        "                # loss = mseloss(x_de, x)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                x_eval = x.data.cpu().numpy()\n",
        "                label_eval = label.data.cpu().numpy()\n",
        "                running_loss += loss.data.cpu().numpy()\n",
        "                if i % 10 == 9:    # print every 10 mini-batches\n",
        "                    print('[%d, %5d] loss: %.7f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 10))\n",
        "                    running_loss = 0.0\n",
        "            #now we evaluate the accuracy with AE\n",
        "            dec_ae.eval()\n",
        "            currentAcc = self.validateOnCompleteTestData(test_loader,dec_ae)\n",
        "            if currentAcc > best_acc:                \n",
        "                torch.save(dec_ae,'pretrain_EnDe.pth'.format(best_acc))\n",
        "                best_acc = currentAcc\n",
        "    def clustering(self,mbk,x,model):\n",
        "        model.eval()\n",
        "        y_pred_ae,_ = model(x)\n",
        "        y_pred_ae = y_pred_ae.data.cpu().numpy()\n",
        "        y_pred = mbk.partial_fit(y_pred_ae) #seems we can only get a centre from batch\n",
        "        self.cluster_centers = mbk.cluster_centers_ #keep the cluster centers\n",
        "        model.updateClusterCenter(self.cluster_centers)\n",
        "    def train(self,train_loader, test_loader, epochs):\n",
        "        \"\"\"This method will start training for DEC cluster\"\"\"\n",
        "        ct = time.time()\n",
        "        model = torch.load(\"pretrain_EnDe.pth\").cuda()\n",
        "        model.setPretrain(False)\n",
        "        optimizer = optim.SGD([{'params': model.parameters()}, ],lr = 0.0001, momentum=0.9)\n",
        "        # optimizer = optim.Adam([{'params': model.parameters()}, ],lr = 0.1) #, momentum=0.9\n",
        "        print('Initializing cluster center with pre-trained weights')\n",
        "        mbk = MiniBatchKMeans(n_clusters=self.n_clusters, n_init=20, batch_size=batch_size)\n",
        "        got_cluster_center = False\n",
        "        for epoch in range(epochs):\n",
        "            for i,data in enumerate(train_loader):\n",
        "                x, label = data\n",
        "                x = Variable(x).cuda()\n",
        "                optimizer.zero_grad()\n",
        "                #step 1 - get cluster center from batch\n",
        "                #here we are using minibatch kmeans to be able to cope with larger dataset.\n",
        "                if not got_cluster_center:\n",
        "                    self.clustering(mbk,x,model)\n",
        "                    if epoch > 1:\n",
        "                        got_cluster_center = True\n",
        "                else:\n",
        "                    model.train()\n",
        "                    #now we start training with acquired cluster center\n",
        "                    feature_pred,q = model(x)\n",
        "                    #get target distribution\n",
        "                    p = self.target_distribution(q)\n",
        "                    #print('q',q,'p',p)\n",
        "                    loss = self.kld(q,p).mean()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "            currentAcc = self.validateOnCompleteTestData(test_loader,model)\n",
        "        # return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l1TSI0HVCw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5777ca-849a-4c35-b82a-add20e9246f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    10] loss: 0.4577536\n",
            "[1,    20] loss: 0.4961189\n",
            "        |==>  acc: 0.5125,  nmi: 0.0005  <==|\n",
            "[2,    10] loss: 0.4674316\n",
            "[2,    20] loss: 0.5120804\n",
            "        |==>  acc: 0.5375,  nmi: 0.0042  <==|\n",
            "[3,    10] loss: 0.4531930\n",
            "[3,    20] loss: 0.5124784\n",
            "        |==>  acc: 0.5375,  nmi: 0.0042  <==|\n",
            "[4,    10] loss: 0.4846529\n",
            "[4,    20] loss: 0.4830212\n",
            "        |==>  acc: 0.5375,  nmi: 0.0042  <==|\n",
            "[5,    10] loss: 0.4722325\n",
            "[5,    20] loss: 0.5013712\n",
            "        |==>  acc: 0.5125,  nmi: 0.0005  <==|\n",
            "[6,    10] loss: 0.4947464\n",
            "[6,    20] loss: 0.4683196\n",
            "        |==>  acc: 0.5625,  nmi: 0.0118  <==|\n",
            "[7,    10] loss: 0.4753345\n",
            "[7,    20] loss: 0.4840784\n",
            "        |==>  acc: 0.5375,  nmi: 0.0042  <==|\n",
            "[8,    10] loss: 0.5079423\n",
            "[8,    20] loss: 0.4538487\n",
            "        |==>  acc: 0.6125,  nmi: 0.0385  <==|\n",
            "[9,    10] loss: 0.4574465\n",
            "[9,    20] loss: 0.5082907\n",
            "        |==>  acc: 0.6375,  nmi: 0.0578  <==|\n",
            "[10,    10] loss: 0.4724823\n",
            "[10,    20] loss: 0.4842722\n",
            "        |==>  acc: 0.5375,  nmi: 0.0042  <==|\n",
            "[11,    10] loss: 0.4959437\n",
            "[11,    20] loss: 0.4645173\n",
            "        |==>  acc: 0.5125,  nmi: 0.0005  <==|\n",
            "[12,    10] loss: 0.4944055\n",
            "[12,    20] loss: 0.4659424\n",
            "        |==>  acc: 0.5375,  nmi: 0.0042  <==|\n",
            "[13,    10] loss: 0.4961118\n",
            "[13,    20] loss: 0.4456352\n",
            "        |==>  acc: 0.5625,  nmi: 0.0118  <==|\n",
            "[14,    10] loss: 0.4940097\n",
            "[14,    20] loss: 0.4679997\n",
            "        |==>  acc: 0.5875,  nmi: 0.0232  <==|\n",
            "[15,    10] loss: 0.4879191\n",
            "[15,    20] loss: 0.4775241\n",
            "        |==>  acc: 0.5375,  nmi: 0.0042  <==|\n"
          ]
        }
      ],
      "source": [
        "#now start training\n",
        "import random\n",
        "# random.seed(7)\n",
        "dec = DEC(2)\n",
        "dec.pretrain(train_loader, test_loader, 15) ## parameter initialze"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec.train(train_loader, test_loader, 15) ## DEC train"
      ],
      "metadata": {
        "id": "Fz0k46mBjs0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21ce26f-e260-4d4a-ac0c-f43756dd65d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing cluster center with pre-trained weights\n",
            "        |==>  acc: 0.5625,  nmi: 0.0118  <==|\n",
            "        |==>  acc: 0.5375,  nmi: 0.0042  <==|\n",
            "        |==>  acc: 0.5125,  nmi: 0.0005  <==|\n",
            "        |==>  acc: 0.5250,  nmi: 0.0019  <==|\n",
            "        |==>  acc: 0.5500,  nmi: 0.0076  <==|\n",
            "        |==>  acc: 0.5750,  nmi: 0.0172  <==|\n",
            "        |==>  acc: 0.6000,  nmi: 0.0308  <==|\n",
            "        |==>  acc: 0.5250,  nmi: 0.0019  <==|\n",
            "        |==>  acc: 0.5250,  nmi: 0.0019  <==|\n",
            "        |==>  acc: 0.5250,  nmi: 0.0019  <==|\n",
            "        |==>  acc: 0.5625,  nmi: 0.0118  <==|\n",
            "        |==>  acc: 0.5250,  nmi: 0.0019  <==|\n",
            "        |==>  acc: 0.5250,  nmi: 0.0019  <==|\n",
            "        |==>  acc: 0.5250,  nmi: 0.0019  <==|\n",
            "        |==>  acc: 0.5250,  nmi: 0.0019  <==|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder + Decoder Model"
      ],
      "metadata": {
        "id": "r2K8eQv6TAIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, in_features, nb_classes, pretrained):\n",
        "        super(MyModel, self).__init__()\n",
        "        if nb_classes==2:\n",
        "          self.nb_classes=1\n",
        "\n",
        "        self.pretrained = pretrained\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32,out_channels=1,kernel_size=3, stride=2)\n",
        "        self.relu = nn.ReLU() \n",
        "        self.final_fc = nn.Linear(225, self.nb_classes)\n",
        "        self.flaten = nn.Flatten()\n",
        "        # self.dropout = nn.Dropout2d(0.4)\n",
        "        self.out = nn.Softmax()  # for hinge loss turn it off\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.pretrained.eval()\n",
        "        # x, _ = self.pretrained(x) # encoder output\n",
        "        _, x = self.pretrained(x) # decoder output\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # x = self.conv1(x)\n",
        "        # x = self.relu(x)\n",
        "\n",
        "        # x = self.dropout(x)\n",
        "\n",
        "        x = self.flaten(x)\n",
        "        x   = self.final_fc(x) \n",
        "        x = self.out(x) # turn it off for hingeloss\n",
        "        return x"
      ],
      "metadata": {
        "id": "lFgY0EwB0dQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "tcHY7dCz_VqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0935248-4030-4033-9724-c1e1bc9b719f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## load pretrained mdoel \n",
        "pretrained = torch.load(\"pretrain_EnDe.pth\")\n",
        "model = MyModel(10,2,pretrained)\n",
        "summary(model, input_size=(10,1,128,128))"
      ],
      "metadata": {
        "id": "lIOs4dYH0ZxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5b86f0-c895-4483-9389-007d69ecfef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MyModel                                  [10, 1]                   --\n",
              "├─DEC_AE: 1-1                            [10, 10]                  20\n",
              "│    └─Dropout: 2-1                      [10, 16384]               --\n",
              "│    └─Linear: 2-2                       [10, 500]                 8,192,500\n",
              "│    └─ReLU: 2-3                         [10, 500]                 --\n",
              "│    └─Linear: 2-4                       [10, 500]                 250,500\n",
              "│    └─ReLU: 2-5                         [10, 500]                 --\n",
              "│    └─Linear: 2-6                       [10, 2000]                1,002,000\n",
              "│    └─ReLU: 2-7                         [10, 2000]                --\n",
              "│    └─Linear: 2-8                       [10, 10]                  20,010\n",
              "│    └─Linear: 2-9                       [10, 2000]                22,000\n",
              "│    └─ReLU: 2-10                        [10, 2000]                --\n",
              "│    └─Linear: 2-11                      [10, 500]                 1,000,500\n",
              "│    └─ReLU: 2-12                        [10, 500]                 --\n",
              "│    └─Linear: 2-13                      [10, 500]                 250,500\n",
              "│    └─ReLU: 2-14                        [10, 500]                 --\n",
              "│    └─Linear: 2-15                      [10, 16384]               8,208,384\n",
              "├─Conv2d: 1-2                            [10, 16, 63, 63]          160\n",
              "├─ReLU: 1-3                              [10, 16, 63, 63]          --\n",
              "├─Conv2d: 1-4                            [10, 32, 31, 31]          4,640\n",
              "├─ReLU: 1-5                              [10, 32, 31, 31]          --\n",
              "├─Conv2d: 1-6                            [10, 1, 15, 15]           289\n",
              "├─ReLU: 1-7                              [10, 1, 15, 15]           --\n",
              "├─Flatten: 1-8                           [10, 225]                 --\n",
              "├─Linear: 1-9                            [10, 1]                   226\n",
              "├─Softmax: 1-10                          [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 18,951,729\n",
              "Trainable params: 18,951,729\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 241.06\n",
              "==========================================================================================\n",
              "Input size (MB): 0.66\n",
              "Forward/backward pass size (MB): 9.35\n",
              "Params size (MB): 75.81\n",
              "Estimated Total Size (MB): 85.81\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [suggested BCEWithLogitsLoss or CrossEntropyLoss](https://discuss.pytorch.org/t/model-accuracy-stuck-at-0-5-though-loss-is-consistently-decreasing/72343/4)"
      ],
      "metadata": {
        "id": "h1iiEg-TXWKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "device ='cuda'\n",
        "model = model.to(device)\n",
        "\n",
        "criterion =  nn.BCEWithLogitsLoss() ## suggested in the above link\n",
        "# criterion = nn.CrossEntropyLoss() ## suggested in the above link ## good for imbalanced dataset\n",
        "\n",
        "# criterion =  nn.BCELoss()\n",
        "# criterion =  nn.HingeEmbeddingLoss()\n",
        "\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "# optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=0.1) ##.1, .01, .001, .2\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "n_epochs = 20"
      ],
      "metadata": {
        "id": "hJRZAfbZkR6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## UPPER Atmospheric Data\n",
        "train_csv = '/content/drive/MyDrive/Seraj/skybased-128-downstream/downstream_sky_train.csv'\n",
        "test_csv = '/content/drive/MyDrive/Seraj/skybased-128-downstream/downstream_sky_test.csv'\n",
        "root_dir = '/content/drive/MyDrive/Seraj/skybased-128-downstream'"
      ],
      "metadata": {
        "id": "b08Z7mLVpnLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "train_set = MyDataset(train_csv,root_dir)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=train_set,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=True)\n",
        "test_set = MyDataset(test_csv, root_dir)\n",
        "# test_set = MyDataset(test_csv,root_dir)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=test_set,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=False)\n",
        "\n",
        "data_sample = train_loader.dataset[0]\n",
        "x,y = data_sample\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "EYkboV9ApnLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565fb1c3-977b-4756-9126-6f5119d93e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_acc = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    running_loss=0.0\n",
        "    train_epoch_loss = []\n",
        "    train_epoch_acc = []\n",
        "    for i,data in enumerate(train_loader):\n",
        "      x, label = data\n",
        "      x, label = Variable(x).cuda(),Variable(label).float().cuda()\n",
        "      optimizer_ft.zero_grad()\n",
        "      pred = model(x)\n",
        "  \n",
        "      label = torch.unsqueeze(label,1)\n",
        "      loss = criterion(pred,label)\n",
        "      loss.backward()\n",
        "      optimizer_ft.step()\n",
        "      \n",
        "      y_true = label.cpu().numpy().astype(int)\n",
        "      y_pred = pred.cpu().detach().numpy()\n",
        "      y_pred = np.argmax(y_pred,axis=1)\n",
        "      accuracy = acc(y_pred,y_true)\n",
        "\n",
        "      train_epoch_acc.append(accuracy)\n",
        "      train_epoch_loss.append(loss.data.cpu().numpy())\n",
        "\n",
        "      print('[%d, %5d] loss: %.7f' % (epoch + 1, i + 1, loss.data.cpu().numpy() ))\n",
        "      print('acc', np.average(train_epoch_acc), 'loss',np.average(train_epoch_loss))\n"
      ],
      "metadata": {
        "id": "38XMJwn9P_gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3228b10-1c38-4291-f6eb-e0151e96a48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.8132618\n",
            "[1,     2] loss: 1.0132618\n",
            "[1,     3] loss: 0.9132618\n",
            "[1,     4] loss: 0.8132618\n",
            "[1,     5] loss: 0.8132618\n",
            "[1,     6] loss: 0.5132617\n",
            "[1,     7] loss: 0.8132618\n",
            "[1,     8] loss: 0.7132618\n",
            "[1,     9] loss: 1.2132618\n",
            "[1,    10] loss: 0.7132618\n",
            "[1,    11] loss: 0.7132618\n",
            "[1,    12] loss: 1.0132618\n",
            "[1,    13] loss: 0.7132618\n",
            "[1,    14] loss: 0.9132618\n",
            "[1,    15] loss: 0.8132618\n",
            "[1,    16] loss: 0.7132618\n",
            "[1,    17] loss: 0.6132618\n",
            "[1,    18] loss: 1.0132618\n",
            "[1,    19] loss: 0.8132618\n",
            "[1,    20] loss: 0.6132618\n",
            "[1,    21] loss: 0.9132618\n",
            "[1,    22] loss: 0.7132618\n",
            "acc 0.618181818181818 loss 0.8132618\n",
            "[2,     1] loss: 0.8132618\n",
            "[2,     2] loss: 0.9132618\n",
            "[2,     3] loss: 0.9132618\n",
            "[2,     4] loss: 0.7132618\n",
            "[2,     5] loss: 0.9132618\n",
            "[2,     6] loss: 0.9132618\n",
            "[2,     7] loss: 0.6132618\n",
            "[2,     8] loss: 0.7132618\n",
            "[2,     9] loss: 0.8132618\n",
            "[2,    10] loss: 0.8132618\n",
            "[2,    11] loss: 0.6132618\n",
            "[2,    12] loss: 1.0132618\n",
            "[2,    13] loss: 0.7132618\n",
            "[2,    14] loss: 1.2132618\n",
            "[2,    15] loss: 0.7132618\n",
            "[2,    16] loss: 0.7132618\n",
            "[2,    17] loss: 0.7132618\n",
            "[2,    18] loss: 0.7132618\n",
            "[2,    19] loss: 0.9132618\n",
            "[2,    20] loss: 1.0132618\n",
            "[2,    21] loss: 0.6132618\n",
            "[2,    22] loss: 0.8132618\n",
            "acc 0.618181818181818 loss 0.81326175\n",
            "[3,     1] loss: 0.6132618\n",
            "[3,     2] loss: 0.8132618\n",
            "[3,     3] loss: 0.9132618\n",
            "[3,     4] loss: 0.8132618\n",
            "[3,     5] loss: 0.8132618\n",
            "[3,     6] loss: 1.1132618\n",
            "[3,     7] loss: 0.8132618\n",
            "[3,     8] loss: 0.8132618\n",
            "[3,     9] loss: 0.8132618\n",
            "[3,    10] loss: 0.8132618\n",
            "[3,    11] loss: 1.0132618\n",
            "[3,    12] loss: 0.8132618\n",
            "[3,    13] loss: 0.8132618\n",
            "[3,    14] loss: 0.7132618\n",
            "[3,    15] loss: 0.6132618\n",
            "[3,    16] loss: 0.8132618\n",
            "[3,    17] loss: 1.0132618\n",
            "[3,    18] loss: 1.0132618\n",
            "[3,    19] loss: 0.5132617\n",
            "[3,    20] loss: 0.6132618\n",
            "[3,    21] loss: 0.9132618\n",
            "[3,    22] loss: 0.7132618\n",
            "acc 0.5999999999999999 loss 0.8132618\n",
            "[4,     1] loss: 0.7132618\n",
            "[4,     2] loss: 0.9132618\n",
            "[4,     3] loss: 0.7132618\n",
            "[4,     4] loss: 1.0132618\n",
            "[4,     5] loss: 1.0132618\n",
            "[4,     6] loss: 0.6132618\n",
            "[4,     7] loss: 1.0132618\n",
            "[4,     8] loss: 1.0132618\n",
            "[4,     9] loss: 0.6132618\n",
            "[4,    10] loss: 0.8132618\n",
            "[4,    11] loss: 0.8132618\n",
            "[4,    12] loss: 0.8132618\n",
            "[4,    13] loss: 0.8132618\n",
            "[4,    14] loss: 0.6132618\n",
            "[4,    15] loss: 0.8132618\n",
            "[4,    16] loss: 0.8132618\n",
            "[4,    17] loss: 0.6132618\n",
            "[4,    18] loss: 0.9132618\n",
            "[4,    19] loss: 1.0132618\n",
            "[4,    20] loss: 0.6132618\n",
            "[4,    21] loss: 0.8132618\n",
            "[4,    22] loss: 0.8132618\n",
            "acc 0.6090909090909089 loss 0.81326175\n",
            "[5,     1] loss: 0.8132618\n",
            "[5,     2] loss: 0.6132618\n",
            "[5,     3] loss: 0.8132618\n",
            "[5,     4] loss: 0.8132618\n",
            "[5,     5] loss: 0.8132618\n",
            "[5,     6] loss: 0.7132618\n",
            "[5,     7] loss: 1.0132618\n",
            "[5,     8] loss: 0.8132618\n",
            "[5,     9] loss: 0.9132618\n",
            "[5,    10] loss: 0.7132618\n",
            "[5,    11] loss: 0.8132618\n",
            "[5,    12] loss: 1.0132618\n",
            "[5,    13] loss: 0.8132618\n",
            "[5,    14] loss: 0.6132618\n",
            "[5,    15] loss: 1.1132618\n",
            "[5,    16] loss: 0.8132618\n",
            "[5,    17] loss: 0.8132618\n",
            "[5,    18] loss: 1.0132618\n",
            "[5,    19] loss: 0.8132618\n",
            "[5,    20] loss: 0.8132618\n",
            "[5,    21] loss: 0.6132618\n",
            "[5,    22] loss: 0.6132618\n",
            "acc 0.5909090909090907 loss 0.8132618\n",
            "[6,     1] loss: 1.2132618\n",
            "[6,     2] loss: 0.7132618\n",
            "[6,     3] loss: 0.9132618\n",
            "[6,     4] loss: 0.5132617\n",
            "[6,     5] loss: 0.8132618\n",
            "[6,     6] loss: 0.7132618\n",
            "[6,     7] loss: 0.8132618\n",
            "[6,     8] loss: 0.7132618\n",
            "[6,     9] loss: 0.9132618\n",
            "[6,    10] loss: 0.7132618\n",
            "[6,    11] loss: 0.6132618\n",
            "[6,    12] loss: 0.7132618\n",
            "[6,    13] loss: 0.7132618\n",
            "[6,    14] loss: 0.9132618\n",
            "[6,    15] loss: 0.7132618\n",
            "[6,    16] loss: 0.9132618\n",
            "[6,    17] loss: 1.1132618\n",
            "[6,    18] loss: 0.8132618\n",
            "[6,    19] loss: 0.9132618\n",
            "[6,    20] loss: 0.7132618\n",
            "[6,    21] loss: 1.0132618\n",
            "[6,    22] loss: 0.7132618\n",
            "acc 0.6272727272727272 loss 0.8132618\n",
            "[7,     1] loss: 0.7132618\n",
            "[7,     2] loss: 0.9132618\n",
            "[7,     3] loss: 0.8132618\n",
            "[7,     4] loss: 0.8132618\n",
            "[7,     5] loss: 1.0132618\n",
            "[7,     6] loss: 0.7132618\n",
            "[7,     7] loss: 0.6132618\n",
            "[7,     8] loss: 0.9132618\n",
            "[7,     9] loss: 0.5132617\n",
            "[7,    10] loss: 0.8132618\n",
            "[7,    11] loss: 0.8132618\n",
            "[7,    12] loss: 0.9132618\n",
            "[7,    13] loss: 0.7132618\n",
            "[7,    14] loss: 0.8132618\n",
            "[7,    15] loss: 0.5132617\n",
            "[7,    16] loss: 1.3132619\n",
            "[7,    17] loss: 0.7132618\n",
            "[7,    18] loss: 1.0132618\n",
            "[7,    19] loss: 0.7132618\n",
            "[7,    20] loss: 1.1132618\n",
            "[7,    21] loss: 0.7132618\n",
            "[7,    22] loss: 0.7132618\n",
            "acc 0.6363636363636362 loss 0.8132619\n",
            "[8,     1] loss: 0.7132618\n",
            "[8,     2] loss: 1.0132618\n",
            "[8,     3] loss: 0.7132618\n",
            "[8,     4] loss: 0.7132618\n",
            "[8,     5] loss: 0.7132618\n",
            "[8,     6] loss: 0.8132618\n",
            "[8,     7] loss: 0.9132618\n",
            "[8,     8] loss: 1.0132618\n",
            "[8,     9] loss: 0.9132618\n",
            "[8,    10] loss: 0.7132618\n",
            "[8,    11] loss: 0.9132618\n",
            "[8,    12] loss: 0.6132618\n",
            "[8,    13] loss: 0.8132618\n",
            "[8,    14] loss: 0.8132618\n",
            "[8,    15] loss: 0.9132618\n",
            "[8,    16] loss: 0.7132618\n",
            "[8,    17] loss: 0.8132618\n",
            "[8,    18] loss: 0.7132618\n",
            "[8,    19] loss: 0.8132618\n",
            "[8,    20] loss: 0.4132617\n",
            "[8,    21] loss: 1.0132618\n",
            "[8,    22] loss: 1.1132618\n",
            "acc 0.6181818181818182 loss 0.8132618\n",
            "[9,     1] loss: 1.0132618\n",
            "[9,     2] loss: 0.8132618\n",
            "[9,     3] loss: 0.8132618\n",
            "[9,     4] loss: 0.7132618\n",
            "[9,     5] loss: 0.7132618\n",
            "[9,     6] loss: 1.0132618\n",
            "[9,     7] loss: 0.6132618\n",
            "[9,     8] loss: 1.0132618\n",
            "[9,     9] loss: 0.7132618\n",
            "[9,    10] loss: 0.7132618\n",
            "[9,    11] loss: 0.8132618\n",
            "[9,    12] loss: 0.4132617\n",
            "[9,    13] loss: 0.9132618\n",
            "[9,    14] loss: 1.0132618\n",
            "[9,    15] loss: 0.9132618\n",
            "[9,    16] loss: 0.7132618\n",
            "[9,    17] loss: 0.6132618\n",
            "[9,    18] loss: 1.0132618\n",
            "[9,    19] loss: 0.8132618\n",
            "[9,    20] loss: 0.9132618\n",
            "[9,    21] loss: 0.9132618\n",
            "[9,    22] loss: 0.7132618\n",
            "acc 0.6272727272727271 loss 0.8132618\n",
            "[10,     1] loss: 1.0132618\n",
            "[10,     2] loss: 0.8132618\n",
            "[10,     3] loss: 0.8132618\n",
            "[10,     4] loss: 0.6132618\n",
            "[10,     5] loss: 1.0132618\n",
            "[10,     6] loss: 0.7132618\n",
            "[10,     7] loss: 0.9132618\n",
            "[10,     8] loss: 1.1132618\n",
            "[10,     9] loss: 0.8132618\n",
            "[10,    10] loss: 0.7132618\n",
            "[10,    11] loss: 0.8132618\n",
            "[10,    12] loss: 0.7132618\n",
            "[10,    13] loss: 0.8132618\n",
            "[10,    14] loss: 0.7132618\n",
            "[10,    15] loss: 0.8132618\n",
            "[10,    16] loss: 0.7132618\n",
            "[10,    17] loss: 0.7132618\n",
            "[10,    18] loss: 0.8132618\n",
            "[10,    19] loss: 0.7132618\n",
            "[10,    20] loss: 0.8132618\n",
            "[10,    21] loss: 0.9132618\n",
            "[10,    22] loss: 0.8132618\n",
            "acc 0.5818181818181818 loss 0.81326175\n",
            "[11,     1] loss: 0.9132618\n",
            "[11,     2] loss: 0.8132618\n",
            "[11,     3] loss: 0.8132618\n",
            "[11,     4] loss: 0.7132618\n",
            "[11,     5] loss: 0.8132618\n",
            "[11,     6] loss: 0.7132618\n",
            "[11,     7] loss: 0.7132618\n",
            "[11,     8] loss: 1.1132618\n",
            "[11,     9] loss: 0.8132618\n",
            "[11,    10] loss: 0.8132618\n",
            "[11,    11] loss: 1.1132618\n",
            "[11,    12] loss: 0.8132618\n",
            "[11,    13] loss: 0.9132618\n",
            "[11,    14] loss: 0.7132618\n",
            "[11,    15] loss: 0.5132617\n",
            "[11,    16] loss: 0.7132618\n",
            "[11,    17] loss: 0.8132618\n",
            "[11,    18] loss: 0.6132618\n",
            "[11,    19] loss: 0.9132618\n",
            "[11,    20] loss: 0.9132618\n",
            "[11,    21] loss: 0.5132617\n",
            "[11,    22] loss: 1.1132618\n",
            "acc 0.6181818181818182 loss 0.8132618\n",
            "[12,     1] loss: 1.0132618\n",
            "[12,     2] loss: 0.8132618\n",
            "[12,     3] loss: 0.6132618\n",
            "[12,     4] loss: 0.9132618\n",
            "[12,     5] loss: 0.7132618\n",
            "[12,     6] loss: 1.0132618\n",
            "[12,     7] loss: 0.8132618\n",
            "[12,     8] loss: 0.7132618\n",
            "[12,     9] loss: 0.7132618\n",
            "[12,    10] loss: 0.8132618\n",
            "[12,    11] loss: 1.0132618\n",
            "[12,    12] loss: 0.9132618\n",
            "[12,    13] loss: 0.8132618\n",
            "[12,    14] loss: 0.8132618\n",
            "[12,    15] loss: 0.8132618\n",
            "[12,    16] loss: 0.6132618\n",
            "[12,    17] loss: 0.7132618\n",
            "[12,    18] loss: 1.0132618\n",
            "[12,    19] loss: 0.8132618\n",
            "[12,    20] loss: 0.8132618\n",
            "[12,    21] loss: 0.7132618\n",
            "[12,    22] loss: 0.7132618\n",
            "acc 0.5909090909090908 loss 0.8132618\n",
            "[13,     1] loss: 0.8132618\n",
            "[13,     2] loss: 0.6132618\n",
            "[13,     3] loss: 0.8132618\n",
            "[13,     4] loss: 0.6132618\n",
            "[13,     5] loss: 0.7132618\n",
            "[13,     6] loss: 0.8132618\n",
            "[13,     7] loss: 1.1132618\n",
            "[13,     8] loss: 0.6132618\n",
            "[13,     9] loss: 0.7132618\n",
            "[13,    10] loss: 1.1132618\n",
            "[13,    11] loss: 1.0132618\n",
            "[13,    12] loss: 0.6132618\n",
            "[13,    13] loss: 1.0132618\n",
            "[13,    14] loss: 0.8132618\n",
            "[13,    15] loss: 0.9132618\n",
            "[13,    16] loss: 0.9132618\n",
            "[13,    17] loss: 0.7132618\n",
            "[13,    18] loss: 0.7132618\n",
            "[13,    19] loss: 0.8132618\n",
            "[13,    20] loss: 0.7132618\n",
            "[13,    21] loss: 0.8132618\n",
            "[13,    22] loss: 0.9132618\n",
            "acc 0.618181818181818 loss 0.81326175\n",
            "[14,     1] loss: 0.9132618\n",
            "[14,     2] loss: 0.7132618\n",
            "[14,     3] loss: 0.5132617\n",
            "[14,     4] loss: 0.8132618\n",
            "[14,     5] loss: 0.8132618\n",
            "[14,     6] loss: 0.8132618\n",
            "[14,     7] loss: 0.8132618\n",
            "[14,     8] loss: 0.6132618\n",
            "[14,     9] loss: 0.7132618\n",
            "[14,    10] loss: 0.9132618\n",
            "[14,    11] loss: 0.7132618\n",
            "[14,    12] loss: 1.0132618\n",
            "[14,    13] loss: 0.8132618\n",
            "[14,    14] loss: 0.8132618\n",
            "[14,    15] loss: 0.6132618\n",
            "[14,    16] loss: 0.7132618\n",
            "[14,    17] loss: 0.7132618\n",
            "[14,    18] loss: 1.1132618\n",
            "[14,    19] loss: 1.1132618\n",
            "[14,    20] loss: 0.9132618\n",
            "[14,    21] loss: 1.0132618\n",
            "[14,    22] loss: 0.7132618\n",
            "acc 0.6181818181818182 loss 0.8132618\n",
            "[15,     1] loss: 0.9132618\n",
            "[15,     2] loss: 1.1132618\n",
            "[15,     3] loss: 0.6132618\n",
            "[15,     4] loss: 0.5132617\n",
            "[15,     5] loss: 0.9132618\n",
            "[15,     6] loss: 0.8132618\n",
            "[15,     7] loss: 1.0132618\n",
            "[15,     8] loss: 0.8132618\n",
            "[15,     9] loss: 0.9132618\n",
            "[15,    10] loss: 0.8132618\n",
            "[15,    11] loss: 0.6132618\n",
            "[15,    12] loss: 0.9132618\n",
            "[15,    13] loss: 0.7132618\n",
            "[15,    14] loss: 0.8132618\n",
            "[15,    15] loss: 0.7132618\n",
            "[15,    16] loss: 0.6132618\n",
            "[15,    17] loss: 1.0132618\n",
            "[15,    18] loss: 0.6132618\n",
            "[15,    19] loss: 0.8132618\n",
            "[15,    20] loss: 0.7132618\n",
            "[15,    21] loss: 1.1132618\n",
            "[15,    22] loss: 0.8132618\n",
            "acc 0.6272727272727272 loss 0.8132618\n",
            "[16,     1] loss: 0.6132618\n",
            "[16,     2] loss: 0.9132618\n",
            "[16,     3] loss: 0.7132618\n",
            "[16,     4] loss: 0.8132618\n",
            "[16,     5] loss: 0.8132618\n",
            "[16,     6] loss: 0.5132617\n",
            "[16,     7] loss: 0.7132618\n",
            "[16,     8] loss: 0.8132618\n",
            "[16,     9] loss: 0.6132618\n",
            "[16,    10] loss: 1.0132618\n",
            "[16,    11] loss: 0.8132618\n",
            "[16,    12] loss: 0.9132618\n",
            "[16,    13] loss: 0.8132618\n",
            "[16,    14] loss: 1.0132618\n",
            "[16,    15] loss: 0.6132618\n",
            "[16,    16] loss: 0.9132618\n",
            "[16,    17] loss: 0.7132618\n",
            "[16,    18] loss: 0.6132618\n",
            "[16,    19] loss: 0.8132618\n",
            "[16,    20] loss: 1.0132618\n",
            "[16,    21] loss: 0.9132618\n",
            "[16,    22] loss: 1.2132618\n",
            "acc 0.6272727272727272 loss 0.8132618\n",
            "[17,     1] loss: 0.9132618\n",
            "[17,     2] loss: 0.4132617\n",
            "[17,     3] loss: 0.8132618\n",
            "[17,     4] loss: 0.7132618\n",
            "[17,     5] loss: 0.7132618\n",
            "[17,     6] loss: 0.7132618\n",
            "[17,     7] loss: 0.9132618\n",
            "[17,     8] loss: 0.9132618\n",
            "[17,     9] loss: 0.7132618\n",
            "[17,    10] loss: 0.7132618\n",
            "[17,    11] loss: 0.9132618\n",
            "[17,    12] loss: 0.8132618\n",
            "[17,    13] loss: 0.8132618\n",
            "[17,    14] loss: 0.7132618\n",
            "[17,    15] loss: 0.9132618\n",
            "[17,    16] loss: 1.0132618\n",
            "[17,    17] loss: 0.9132618\n",
            "[17,    18] loss: 0.8132618\n",
            "[17,    19] loss: 1.0132618\n",
            "[17,    20] loss: 0.6132618\n",
            "[17,    21] loss: 0.9132618\n",
            "[17,    22] loss: 0.9132618\n",
            "acc 0.6090909090909089 loss 0.81326175\n",
            "[18,     1] loss: 0.7132618\n",
            "[18,     2] loss: 0.7132618\n",
            "[18,     3] loss: 1.0132618\n",
            "[18,     4] loss: 0.8132618\n",
            "[18,     5] loss: 0.6132618\n",
            "[18,     6] loss: 0.6132618\n",
            "[18,     7] loss: 0.6132618\n",
            "[18,     8] loss: 0.7132618\n",
            "[18,     9] loss: 0.7132618\n",
            "[18,    10] loss: 0.5132617\n",
            "[18,    11] loss: 0.9132618\n",
            "[18,    12] loss: 0.8132618\n",
            "[18,    13] loss: 1.1132618\n",
            "[18,    14] loss: 1.0132618\n",
            "[18,    15] loss: 0.6132618\n",
            "[18,    16] loss: 1.0132618\n",
            "[18,    17] loss: 1.0132618\n",
            "[18,    18] loss: 0.7132618\n",
            "[18,    19] loss: 0.8132618\n",
            "[18,    20] loss: 1.1132618\n",
            "[18,    21] loss: 0.7132618\n",
            "[18,    22] loss: 1.0132618\n",
            "acc 0.6545454545454544 loss 0.8132618\n",
            "[19,     1] loss: 0.8132618\n",
            "[19,     2] loss: 0.5132617\n",
            "[19,     3] loss: 0.8132618\n",
            "[19,     4] loss: 1.1132618\n",
            "[19,     5] loss: 0.6132618\n",
            "[19,     6] loss: 0.8132618\n",
            "[19,     7] loss: 0.9132618\n",
            "[19,     8] loss: 0.8132618\n",
            "[19,     9] loss: 0.8132618\n",
            "[19,    10] loss: 0.9132618\n",
            "[19,    11] loss: 1.0132618\n",
            "[19,    12] loss: 0.6132618\n",
            "[19,    13] loss: 0.8132618\n",
            "[19,    14] loss: 0.8132618\n",
            "[19,    15] loss: 0.6132618\n",
            "[19,    16] loss: 0.9132618\n",
            "[19,    17] loss: 0.7132618\n",
            "[19,    18] loss: 0.8132618\n",
            "[19,    19] loss: 1.0132618\n",
            "[19,    20] loss: 0.7132618\n",
            "[19,    21] loss: 0.8132618\n",
            "[19,    22] loss: 0.9132618\n",
            "acc 0.5999999999999999 loss 0.81326175\n",
            "[20,     1] loss: 0.6132618\n",
            "[20,     2] loss: 0.9132618\n",
            "[20,     3] loss: 0.9132618\n",
            "[20,     4] loss: 0.9132618\n",
            "[20,     5] loss: 0.7132618\n",
            "[20,     6] loss: 0.6132618\n",
            "[20,     7] loss: 0.6132618\n",
            "[20,     8] loss: 0.9132618\n",
            "[20,     9] loss: 0.8132618\n",
            "[20,    10] loss: 1.0132618\n",
            "[20,    11] loss: 0.9132618\n",
            "[20,    12] loss: 0.6132618\n",
            "[20,    13] loss: 0.9132618\n",
            "[20,    14] loss: 0.7132618\n",
            "[20,    15] loss: 0.8132618\n",
            "[20,    16] loss: 0.9132618\n",
            "[20,    17] loss: 0.8132618\n",
            "[20,    18] loss: 0.9132618\n",
            "[20,    19] loss: 0.9132618\n",
            "[20,    20] loss: 1.0132618\n",
            "[20,    21] loss: 0.6132618\n",
            "[20,    22] loss: 0.7132618\n",
            "acc 0.618181818181818 loss 0.8132618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_losses = []\n",
        "test_acc = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for i in range(len(test_loader)):\n",
        "  data = test_loader.dataset[i]\n",
        "  x, label = data\n",
        "  label = torch.Tensor(label)\n",
        "\n",
        "  x, label = Variable(x).cuda(),Variable(label).float().cuda()\n",
        "  optimizer_ft.zero_grad()\n",
        "  pred = model(x)\n",
        "  \n",
        "  label = torch.unsqueeze(label,1)\n",
        "  loss = criterion(pred,label)\n",
        "  \n",
        "  # Acc\n",
        "  y_true = label.cpu().numpy().astype(int)\n",
        "  y_pred = pred.cpu().detach().numpy()\n",
        "  y_pred = np.argmax(y_pred,axis=1)\n",
        "  print(y_pred.shape)\n",
        "  print('newwww', y_true.shape)\n",
        "  accuracy = acc(y_pred,y_true)\n",
        "\n",
        "  test_acc.append(accuracy)\n",
        "\n",
        "  test_losses.append(loss.data.cpu().numpy())\n",
        "\n",
        "  print('[%5d] loss: %.7f' % (i + 1, loss.data.cpu().numpy() ))\n",
        "  print('[%5d] acc: %.7f' % (i + 1, accuracy ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtKGyeE-3IsP",
        "outputId": "2497511a-f2cc-4caa-f283-b7b21693ed74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1,)\n",
            "newwww (1, 1)\n",
            "[    1] loss: 1.3132617\n",
            "[    1] acc: 1.0000000\n",
            "(1,)\n",
            "newwww (1, 1)\n",
            "[    2] loss: 1.3132617\n",
            "[    2] acc: 1.0000000\n",
            "(1,)\n",
            "newwww (1, 1)\n",
            "[    3] loss: 1.3132617\n",
            "[    3] acc: 1.0000000\n",
            "(1,)\n",
            "newwww (1, 1)\n",
            "[    4] loss: 1.3132617\n",
            "[    4] acc: 1.0000000\n",
            "(1,)\n",
            "newwww (1, 1)\n",
            "[    5] loss: 1.3132617\n",
            "[    5] acc: 1.0000000\n",
            "(1,)\n",
            "newwww (1, 1)\n",
            "[    6] loss: 1.3132617\n",
            "[    6] acc: 1.0000000\n",
            "(1,)\n",
            "newwww (1, 1)\n",
            "[    7] loss: 1.3132617\n",
            "[    7] acc: 1.0000000\n",
            "(1,)\n",
            "newwww (1, 1)\n",
            "[    8] loss: 1.3132617\n",
            "[    8] acc: 1.0000000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
